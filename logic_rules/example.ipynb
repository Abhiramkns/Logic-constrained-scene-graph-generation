{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import torch\n",
    "\n",
    "embedding_size = 5\n",
    "\n",
    "# first group of people\n",
    "g1 = {\n",
    "    person: ltn.Constant(torch.rand((embedding_size,)), trainable=True)\n",
    "    for person in \"abcdefgh\"\n",
    "}\n",
    "# second group of people\n",
    "g2 = {\n",
    "    person: ltn.Constant(torch.rand((embedding_size,)), trainable=True)\n",
    "    for person in \"ijklmn\"\n",
    "}\n",
    "# group of all people\n",
    "g = {**g1, **g2}\n",
    "\n",
    "# we define friendship relations, who has cancer and who is a smoker\n",
    "friends = [\n",
    "    (\"a\", \"b\"),\n",
    "    (\"a\", \"e\"),\n",
    "    (\"a\", \"f\"),\n",
    "    (\"a\", \"g\"),\n",
    "    (\"b\", \"c\"),\n",
    "    (\"c\", \"d\"),\n",
    "    (\"e\", \"f\"),\n",
    "    (\"g\", \"h\"),\n",
    "    (\"i\", \"j\"),\n",
    "    (\"j\", \"m\"),\n",
    "    (\"k\", \"l\"),\n",
    "    (\"m\", \"n\"),\n",
    "]\n",
    "family = [(\"a\", \"b\"), (\"a\", \"e\")]\n",
    "smokes = [\"a\", \"e\", \"f\", \"g\", \"j\", \"n\"]\n",
    "cancer = [\"a\", \"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define predicates F, C, and S\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP model used for defining the predicates of our problem.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes=(10, 16, 16, 1)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                for i in range(1, len(layer_sizes))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, *x):\n",
    "        \"\"\"\n",
    "        Given an individual x, the forward phase of this MLP returns the probability that the individual x is a smoker,\n",
    "        or has cancer, or is friend of y (if given and predicate is F).\n",
    "\n",
    "        :param x: individuals for which we have to compute the probability\n",
    "        :return: the probability that individual x is a smoker, or has cancer, or is friend of y (if given)\n",
    "        \"\"\"\n",
    "        x = list(x)\n",
    "        if len(x) == 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat(x, dim=1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "        out = self.sigmoid(self.linear_layers[-1](x))\n",
    "        return out\n",
    "\n",
    "\n",
    "C = ltn.Predicate(MLP(layer_sizes=(5, 16, 16, 1)))\n",
    "S = ltn.Predicate(MLP(layer_sizes=(5, 16, 16, 1)))\n",
    "F = ltn.Predicate(MLP(layer_sizes=(10, 16, 16, 1)))\n",
    "Fa = ltn.Predicate(MLP(layer_sizes=(10, 16, 16, 1)))\n",
    "\n",
    "# we define connectives, quantifiers, and SatAgg\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.4276 | Train Sat 0.572 | Phi1 Sat 0.758 | Phi2 Sat 0.567 | Phi3 Sat 0.854\n",
      " epoch 20 | loss 0.4151 | Train Sat 0.585 | Phi1 Sat 0.752 | Phi2 Sat 0.634 | Phi3 Sat 0.891\n",
      " epoch 40 | loss 0.4047 | Train Sat 0.595 | Phi1 Sat 0.748 | Phi2 Sat 0.682 | Phi3 Sat 0.911\n",
      " epoch 60 | loss 0.3922 | Train Sat 0.608 | Phi1 Sat 0.747 | Phi2 Sat 0.708 | Phi3 Sat 0.927\n",
      " epoch 80 | loss 0.3718 | Train Sat 0.628 | Phi1 Sat 0.758 | Phi2 Sat 0.705 | Phi3 Sat 0.934\n",
      " epoch 100 | loss 0.3452 | Train Sat 0.655 | Phi1 Sat 0.790 | Phi2 Sat 0.690 | Phi3 Sat 0.936\n",
      " epoch 120 | loss 0.3230 | Train Sat 0.677 | Phi1 Sat 0.848 | Phi2 Sat 0.667 | Phi3 Sat 0.940\n",
      " epoch 140 | loss 0.3110 | Train Sat 0.689 | Phi1 Sat 0.894 | Phi2 Sat 0.639 | Phi3 Sat 0.948\n",
      " epoch 160 | loss 0.3059 | Train Sat 0.694 | Phi1 Sat 0.925 | Phi2 Sat 0.615 | Phi3 Sat 0.958\n",
      " epoch 180 | loss 0.3032 | Train Sat 0.697 | Phi1 Sat 0.940 | Phi2 Sat 0.598 | Phi3 Sat 0.967\n",
      " epoch 200 | loss 0.3014 | Train Sat 0.699 | Phi1 Sat 0.949 | Phi2 Sat 0.585 | Phi3 Sat 0.973\n",
      " epoch 220 | loss 0.2977 | Train Sat 0.702 | Phi1 Sat 0.954 | Phi2 Sat 0.562 | Phi3 Sat 0.977\n",
      " epoch 240 | loss 0.2950 | Train Sat 0.705 | Phi1 Sat 0.957 | Phi2 Sat 0.530 | Phi3 Sat 0.980\n",
      " epoch 260 | loss 0.2926 | Train Sat 0.707 | Phi1 Sat 0.960 | Phi2 Sat 0.505 | Phi3 Sat 0.982\n",
      " epoch 280 | loss 0.2903 | Train Sat 0.710 | Phi1 Sat 0.961 | Phi2 Sat 0.489 | Phi3 Sat 0.984\n",
      " epoch 300 | loss 0.2882 | Train Sat 0.712 | Phi1 Sat 0.962 | Phi2 Sat 0.479 | Phi3 Sat 0.986\n",
      " epoch 320 | loss 0.2862 | Train Sat 0.714 | Phi1 Sat 0.963 | Phi2 Sat 0.474 | Phi3 Sat 0.987\n",
      " epoch 340 | loss 0.2839 | Train Sat 0.716 | Phi1 Sat 0.963 | Phi2 Sat 0.471 | Phi3 Sat 0.988\n",
      " epoch 360 | loss 0.2810 | Train Sat 0.719 | Phi1 Sat 0.962 | Phi2 Sat 0.470 | Phi3 Sat 0.989\n",
      " epoch 380 | loss 0.2772 | Train Sat 0.723 | Phi1 Sat 0.961 | Phi2 Sat 0.468 | Phi3 Sat 0.990\n",
      " epoch 400 | loss 0.2716 | Train Sat 0.728 | Phi1 Sat 0.960 | Phi2 Sat 0.463 | Phi3 Sat 0.991\n",
      " epoch 420 | loss 0.2625 | Train Sat 0.738 | Phi1 Sat 0.959 | Phi2 Sat 0.449 | Phi3 Sat 0.991\n",
      " epoch 440 | loss 0.2483 | Train Sat 0.752 | Phi1 Sat 0.957 | Phi2 Sat 0.420 | Phi3 Sat 0.992\n",
      " epoch 460 | loss 0.2336 | Train Sat 0.766 | Phi1 Sat 0.954 | Phi2 Sat 0.376 | Phi3 Sat 0.993\n",
      " epoch 480 | loss 0.2236 | Train Sat 0.776 | Phi1 Sat 0.952 | Phi2 Sat 0.332 | Phi3 Sat 0.993\n",
      " epoch 500 | loss 0.2153 | Train Sat 0.785 | Phi1 Sat 0.951 | Phi2 Sat 0.301 | Phi3 Sat 0.994\n",
      " epoch 520 | loss 0.2080 | Train Sat 0.792 | Phi1 Sat 0.952 | Phi2 Sat 0.278 | Phi3 Sat 0.995\n",
      " epoch 540 | loss 0.2024 | Train Sat 0.798 | Phi1 Sat 0.954 | Phi2 Sat 0.263 | Phi3 Sat 0.995\n",
      " epoch 560 | loss 0.1976 | Train Sat 0.802 | Phi1 Sat 0.956 | Phi2 Sat 0.255 | Phi3 Sat 0.996\n",
      " epoch 580 | loss 0.1934 | Train Sat 0.807 | Phi1 Sat 0.957 | Phi2 Sat 0.250 | Phi3 Sat 0.996\n",
      " epoch 600 | loss 0.1906 | Train Sat 0.809 | Phi1 Sat 0.959 | Phi2 Sat 0.246 | Phi3 Sat 0.996\n",
      " epoch 620 | loss 0.1875 | Train Sat 0.813 | Phi1 Sat 0.961 | Phi2 Sat 0.243 | Phi3 Sat 0.996\n",
      " epoch 640 | loss 0.1833 | Train Sat 0.817 | Phi1 Sat 0.961 | Phi2 Sat 0.241 | Phi3 Sat 0.996\n",
      " epoch 660 | loss 0.1801 | Train Sat 0.820 | Phi1 Sat 0.964 | Phi2 Sat 0.239 | Phi3 Sat 0.996\n",
      " epoch 680 | loss 0.1769 | Train Sat 0.823 | Phi1 Sat 0.964 | Phi2 Sat 0.237 | Phi3 Sat 0.995\n",
      " epoch 700 | loss 0.1745 | Train Sat 0.825 | Phi1 Sat 0.965 | Phi2 Sat 0.235 | Phi3 Sat 0.995\n",
      " epoch 720 | loss 0.1729 | Train Sat 0.827 | Phi1 Sat 0.966 | Phi2 Sat 0.233 | Phi3 Sat 0.995\n",
      " epoch 740 | loss 0.1719 | Train Sat 0.828 | Phi1 Sat 0.966 | Phi2 Sat 0.230 | Phi3 Sat 0.995\n",
      " epoch 760 | loss 0.1712 | Train Sat 0.829 | Phi1 Sat 0.966 | Phi2 Sat 0.228 | Phi3 Sat 0.994\n",
      " epoch 780 | loss 0.1707 | Train Sat 0.829 | Phi1 Sat 0.967 | Phi2 Sat 0.226 | Phi3 Sat 0.994\n",
      " epoch 800 | loss 0.1703 | Train Sat 0.830 | Phi1 Sat 0.967 | Phi2 Sat 0.224 | Phi3 Sat 0.995\n",
      " epoch 820 | loss 0.1700 | Train Sat 0.830 | Phi1 Sat 0.967 | Phi2 Sat 0.223 | Phi3 Sat 0.995\n",
      " epoch 840 | loss 0.1698 | Train Sat 0.830 | Phi1 Sat 0.967 | Phi2 Sat 0.222 | Phi3 Sat 0.995\n",
      " epoch 860 | loss 0.1696 | Train Sat 0.830 | Phi1 Sat 0.967 | Phi2 Sat 0.221 | Phi3 Sat 0.995\n",
      " epoch 880 | loss 0.1695 | Train Sat 0.830 | Phi1 Sat 0.967 | Phi2 Sat 0.220 | Phi3 Sat 0.995\n",
      " epoch 900 | loss 0.1694 | Train Sat 0.831 | Phi1 Sat 0.967 | Phi2 Sat 0.219 | Phi3 Sat 0.995\n",
      " epoch 920 | loss 0.1693 | Train Sat 0.831 | Phi1 Sat 0.967 | Phi2 Sat 0.219 | Phi3 Sat 0.995\n",
      " epoch 940 | loss 0.1693 | Train Sat 0.831 | Phi1 Sat 0.967 | Phi2 Sat 0.218 | Phi3 Sat 0.995\n",
      " epoch 960 | loss 0.1692 | Train Sat 0.831 | Phi1 Sat 0.966 | Phi2 Sat 0.218 | Phi3 Sat 0.995\n",
      " epoch 980 | loss 0.1692 | Train Sat 0.831 | Phi1 Sat 0.966 | Phi2 Sat 0.218 | Phi3 Sat 0.995\n"
     ]
    }
   ],
   "source": [
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "\n",
    "\n",
    "# this function returns the satisfaction level of the logical formula phi 1\n",
    "def phi1():\n",
    "    p = ltn.Variable(\"p\", torch.stack([i.value for i in g.values()]))\n",
    "    return Forall(p, Implies(C(p), S(p)), p=5).value\n",
    "\n",
    "\n",
    "# this function returns the satisfaction level of the logical formula phi2\n",
    "def phi2():\n",
    "    p = ltn.Variable(\"p\", torch.stack([i.value for i in g.values()]))\n",
    "    q = ltn.Variable(\"q\", torch.stack([i.value for i in g.values()]))\n",
    "    return Forall([p, q], Implies(Or(C(p), C(q)), F(p, q)), p=5).value\n",
    "\n",
    "\n",
    "def phi3():\n",
    "    p = ltn.Variable(\"p\", torch.stack([i.value for i in g.values()]))\n",
    "    q = ltn.Variable(\"q\", torch.stack([i.value for i in g.values()]))\n",
    "    return Forall([p, q], Implies(And(C(p), C(q)), Fa(p, q)), p=5).value\n",
    "\n",
    "\n",
    "# we have to optimize the parameters of the three predicates and also of the embeddings\n",
    "params = (\n",
    "    list(S.parameters())\n",
    "    + list(F.parameters())\n",
    "    + list(C.parameters())\n",
    "    + list(Fa.parameters())\n",
    "    + [i.value for i in g.values()]\n",
    ")\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    if epoch <= 200:\n",
    "        p_exists = 1\n",
    "    else:\n",
    "        p_exists = 6\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # ground the variables\n",
    "    \"\"\"\n",
    "    NOTE: we update the embeddings at each step\n",
    "        -> we should re-compute the variables.\n",
    "    \"\"\"\n",
    "    x_ = ltn.Variable(\"x\", torch.stack([i.value for i in g.values()]))\n",
    "    y_ = ltn.Variable(\"y\", torch.stack([i.value for i in g.values()]))\n",
    "\n",
    "    sat_agg = SatAgg(\n",
    "        # Friends: knowledge incomplete in that\n",
    "        #     Friend(x,y) with x<y may be known\n",
    "        #     but Friend(y,x) may not be known\n",
    "        SatAgg(*[F(g[x], g[y]) for (x, y) in friends]),\n",
    "        SatAgg(\n",
    "            *[\n",
    "                Not(F(g[x], g[y]))\n",
    "                for x in g1\n",
    "                for y in g1\n",
    "                if (x, y) not in friends and x < y\n",
    "            ]\n",
    "            + [\n",
    "                Not(F(g[x], g[y]))\n",
    "                for x in g2\n",
    "                for y in g2\n",
    "                if (x, y) not in friends and x < y\n",
    "            ]\n",
    "        ),\n",
    "        # Family\n",
    "        SatAgg(*[F(g[x], g[y]) for (x, y) in family]),\n",
    "        # Smokes: knowledge complete\n",
    "        SatAgg(*[S(g[x]) for x in smokes]),\n",
    "        SatAgg(*[Not(S(g[x])) for x in g if x not in smokes]),\n",
    "        # Cancer: knowledge complete in g1 only\n",
    "        SatAgg(*[C(g[x]) for x in cancer]),\n",
    "        SatAgg(*[Not(C(g[x])) for x in g1 if x not in cancer]),\n",
    "        # friendship is anti-reflexive (note that p=5)\n",
    "        Forall(x_, Not(F(x_, x_)), p=5),\n",
    "        # friendship is symmetric (note that p=5)\n",
    "        Forall([x_, y_], Implies(F(x_, y_), F(y_, x_)), p=5),\n",
    "        # everyone has a friend\n",
    "        Forall(x_, Exists(y_, F(x_, y_), p=p_exists)),\n",
    "        # smoking propagates among friends\n",
    "        Forall([x_, y_], Implies(And(F(x_, y_), S(x_)), S(y_))),\n",
    "        # Smokes implies Friends or Family\n",
    "        Forall([x_, y_], Implies(And(C(x_), C(y_)), Or(F(x_, y_), Fa(x_, y_)))),\n",
    "        # smoking causes cancer + not smoking causes not cancer\n",
    "        Forall(x_, Implies(S(x_), C(x_))),\n",
    "        Forall(x_, Implies(Not(S(x_)), Not(C(x_)))),\n",
    "    )\n",
    "    loss = 1.0 - sat_agg\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\n",
    "            \" epoch %d | loss %.4f | Train Sat %.3f | Phi1 Sat %.3f | Phi2 Sat %.3f | Phi3 Sat %.3f\"\n",
    "            % (epoch, loss, sat_agg, phi1(), phi2(), phi3())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
