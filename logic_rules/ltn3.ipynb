{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 23:17:26.223695: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-21 23:17:26.295456: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-21 23:17:26.295515: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-21 23:17:26.295717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-21 23:17:26.322500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import ltn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "imdb = h5py.File('../data/mini_imdb_1024.h5')\n",
    "sgdb = h5py.File('../data/mini_VG-SGG.h5')\n",
    "\n",
    "import json\n",
    "with open('../data/mini_VG-SGG-dicts.json') as f:\n",
    "    sgdicts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Equiv = ltn.Wrapper_Connective(ltn.fuzzy_ops.Equiv(ltn.fuzzy_ops.And_Prod(),ltn.fuzzy_ops.Implies_Reichenbach()))\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(p=6),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 23:17:28.770227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:28.787339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:28.787374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:28.794424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:28.794557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:28.794576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:29.574809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:29.574862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:29.574868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-21 23:17:29.574889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 23:17:29.574906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "images = ltn.Variable('image', [i for i in range(100)]) # 1000 images\n",
    "objects = ltn.Variable('object', [i for i in range(25)]) # 150 objects\n",
    "subjects = ltn.Variable('subject', [i for i in range(25)]) \n",
    "relationships = ltn.Variable('relationship', [i for i in range(25)]) # 50 relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_image = defaultdict(set)\n",
    "for image in images.tensor:\n",
    "    image = int(image[0])\n",
    "    if sgdb['img_to_first_box'][image] >= 0:\n",
    "        boxes = [b for b in range(sgdb['img_to_first_box'][image], sgdb['img_to_last_box'][image]+1)]\n",
    "        in_image[image] = set([sgdb['labels'][b][0] for b in boxes])\n",
    "\n",
    "def object_in_image(args):\n",
    "    args = tf.stack(args, axis=1)\n",
    "    output = [0] * args.shape[0]\n",
    "    for i, arg in enumerate(args):\n",
    "        object, image = arg\n",
    "        object, image = int(object), int(image)\n",
    "\n",
    "        if object in in_image[image]:\n",
    "            output[i] = 1\n",
    "\n",
    "    return output\n",
    "\n",
    "obj_in_img = ltn.Predicate(object_in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_in_image = [defaultdict(set) for _ in range(len(imdb['images']))]\n",
    "for image in range(len(imdb['images'])):\n",
    "    if sgdb['img_to_first_rel'][image] >= 0:\n",
    "        relations = [i for i in range(sgdb['img_to_first_rel'][image], sgdb['img_to_last_rel'][image]+1)]\n",
    "        for relation in relations:\n",
    "            predicate = sgdb['predicates'][relation][0]\n",
    "            related_objects = tuple([sgdb['labels'][o][0] for o in sgdb['relationships'][relation].tolist()])\n",
    "            related_in_image[image][predicate].add(related_objects)\n",
    "\n",
    "@tf.function\n",
    "def relationship_in_image(args):\n",
    "    output = []\n",
    "\n",
    "    for relationship, subject, object, image in zip(*args):\n",
    "        relationship = int(relationship)\n",
    "        subject, object = int(subject), int(object)\n",
    "        image = int(image)\n",
    "\n",
    "        if (subject, object) in related_in_image[image][relationship]:\n",
    "            output.append(1)\n",
    "        else:\n",
    "            output.append(0)\n",
    "\n",
    "    return output\n",
    "\n",
    "rel_in_img = ltn.Predicate(relationship_in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConnected(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ModelConnected, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation=tf.nn.elu)\n",
    "        self.dense2 = tf.keras.layers.Dense(16, activation=tf.nn.elu)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        relation, subject, object = inputs \n",
    "        x = tf.concat([relation, subject, object], axis=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n",
    "Connected = ltn.Predicate(ModelConnected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.21730459>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "\n",
    "@tf.function\n",
    "def axioms():\n",
    "    axioms = [\n",
    "        Forall(\n",
    "            [images, relationships, subjects, objects],\n",
    "            Or(\n",
    "                And(\n",
    "                    And(\n",
    "                        And(\n",
    "                            obj_in_img([subjects, images]),\n",
    "                            obj_in_img([objects, images])\n",
    "                        ),\n",
    "                        rel_in_img([relationships, subjects, objects, images])\n",
    "                    ),\n",
    "                    Connected([relationships, subjects, objects])\n",
    "                ),\n",
    "                And(\n",
    "                    Not(And(\n",
    "                        And(\n",
    "                            obj_in_img([subjects, images]),\n",
    "                            obj_in_img([objects, images])\n",
    "                        ),\n",
    "                        rel_in_img([relationships, subjects, objects, images])\n",
    "                    )),\n",
    "                    Not(Connected([relationships, subjects, objects]))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    kb = formula_aggregator(axioms)\n",
    "    sat = kb.tensor\n",
    "    return sat\n",
    "\n",
    "axioms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "\n",
    "for epoch in range(2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1 - axioms()\n",
    "        gradients = tape.gradient(loss, Connected.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, Connected.trainable_variables))\n",
    "        print(f'Epoch:{epoch} Loss:{loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "\n",
    "for epoch in range(2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1 - axioms()\n",
    "        gradients = tape.gradient(loss, Connected.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, Connected.trainable_variables))\n",
    "        print(f'Epoch:{epoch} Loss:{loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connected.model.save_weights('./checkpoints/cp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.007911001236093944\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "relations = len(sgdb['relationships'])\n",
    "for image in related_in_image:\n",
    "    for relation in image:\n",
    "        for subject, object in image[relation]:\n",
    "            sub = ltn.Constant(subject, trainable=False)\n",
    "            obj = ltn.Constant(object, trainable=False)\n",
    "            \n",
    "            prediction = int(tf.argmax(Connected([relationships, sub, obj]).tensor).numpy())\n",
    "            if prediction == relation:\n",
    "                accuracy += 1\n",
    "\n",
    "print(f'ACCURACY: {accuracy / relations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_positives = 0\n",
    "False_positives = 0\n",
    "relations = len(sgdb['relationships'])\n",
    "for image in related_in_image:\n",
    "    for relation in image:\n",
    "        for subject, object in image[relation]:\n",
    "            sub = ltn.Constant(subject, trainable=False)\n",
    "            obj = ltn.Constant(object, trainable=False)\n",
    "            \n",
    "            prediction = int(tf.argmax(Connected([relationships, sub, obj]).tensor).numpy())\n",
    "            if prediction == relation:\n",
    "                True_positives += 1\n",
    "            elif:\n",
    "              False_positives += 1\n",
    "\n",
    "print(f'PRECISION: {True_positives / (False_positives+True_positives)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
