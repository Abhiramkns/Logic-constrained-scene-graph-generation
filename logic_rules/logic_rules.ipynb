{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674ec1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import json\n",
    "import ltn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b94b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed88547",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.00001\n",
    "EPOCHS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de01e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(idx, embedding_size=151):\n",
    "    t = [0] * embedding_size\n",
    "    t[idx] = 1\n",
    "    t = torch.tensor(t)\n",
    "    return t.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c5d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGImageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, imdb_h5, sgg_h5, sgg_dict, transform=None, target_transform=None\n",
    "    ):\n",
    "        self.imdb = h5py.File(imdb_h5)\n",
    "        self.sgg = h5py.File(sgg_h5)\n",
    "        with open(sgg_dict) as f:\n",
    "            self.dicts = json.load(f)\n",
    "            self.idx_to_labels = self.dicts[\"idx_to_label\"]\n",
    "            self.label_to_idx = self.dicts[\"label_to_idx\"]\n",
    "            self.idx_to_predicates = self.dicts[\"idx_to_predicate\"]\n",
    "            self.predicates_to_idx = self.dicts[\"predicate_to_idx\"]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        def return_set():\n",
    "            return set()\n",
    "\n",
    "        self.logic_rules = defaultdict(return_set)\n",
    "\n",
    "        for i in range(len(self.sgg[\"relationships\"])):\n",
    "            sub, obj, rel = (\n",
    "                self.sgg[\"relationships\"][i][0],\n",
    "                self.sgg[\"relationships\"][i][1],\n",
    "                self.sgg[\"predicates\"][i],\n",
    "            )\n",
    "            self.logic_rules[\n",
    "                (\n",
    "                    self.idx_to_labels[str(self.sgg[\"labels\"][sub][0])].upper(),\n",
    "                    self.idx_to_predicates[str(rel[0])].upper().replace(\" \", \"_\"),\n",
    "                )\n",
    "            ].add(self.idx_to_labels[str(self.sgg[\"labels\"][obj][0])].upper())\n",
    "\n",
    "        for k in self.logic_rules:\n",
    "            self.logic_rules[k] = list(self.logic_rules[k])\n",
    "\n",
    "        self.g = {label: get_tensor(i) for i, label in enumerate(self.label_to_idx)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imdb[\"images\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.imdb[\"images\"][idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(torch.tensor(image))\n",
    "        image.to(torch.device(device))\n",
    "\n",
    "        start = self.sgg[\"img_to_first_box\"][idx]\n",
    "        end = self.sgg[\"img_to_last_box\"][idx]\n",
    "        object_names = []\n",
    "        if start > 0:\n",
    "            object_names = [self.sgg[\"labels\"][i][0] for i in range(start, end + 1)]\n",
    "        for _ in range(len(object_names), 150):\n",
    "            object_names += [150]\n",
    "\n",
    "        return image, object_names\n",
    "\n",
    "    def get_relations_grounding(self):\n",
    "        dic = {\n",
    "            predicate.upper().replace(\" \", \"_\"): ltn.Constant(get_tensor(idx))\n",
    "            for idx, predicate in enumerate(self.predicates_to_idx)\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def get_logic_rules(self):\n",
    "        return self.logic_rules\n",
    "\n",
    "    def get_object_grounding(self):\n",
    "        dic = {\n",
    "            obj.upper(): ltn.Constant(get_tensor(idx))\n",
    "            for idx, obj in enumerate(self.label_to_idx)\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def colate_fn(self, data):\n",
    "        batch = [d for d in data if d != None]\n",
    "        return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da9d3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement object predicate.\n",
    "\n",
    "\n",
    "class Saved_Model:\n",
    "    def __init__(self, path) -> None:\n",
    "        weights = ResNet50_Weights.DEFAULT\n",
    "        resnet = resnet50(weights=weights)\n",
    "        resnet.fc = torch.nn.Linear(resnet.fc.in_features, 40)\n",
    "        # self.model = resnet.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "    def get_prob(self, x, label):\n",
    "        # prediction = self.model(x)\n",
    "        \n",
    "        return torch.tensor([[1.0 for _ in range(label.shape[0]//BATCH_SIZE)] for _ in range(128)]) # TODO: Get probability of a class\n",
    "\n",
    "\n",
    "saved_model_path = \"\"\n",
    "model = Saved_Model(path=saved_model_path)\n",
    "object_predicate = ltn.Predicate(func=lambda a, b: model.get_prob(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cbd3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"<saved_model_directory>\"\n",
    "sgg_path = \"../data/mini_VG-SGG.h5\"\n",
    "sgg_dict_path = \"../data/mini_VG-SGG-dicts.json\"\n",
    "imdb_path = \"../data/mini_imdb_1024.h5\"\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "train_data = VGImageDataset(\n",
    "    imdb_path, sgg_path, sgg_dict_path, transform=weights.transforms()\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, BATCH_SIZE, shuffle=True, collate_fn=train_data.colate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b57a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define connectives, quantifiers, and SatAgg\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0bae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes=(302, 250, 200, 151)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                for i in range(1, len(layer_sizes))\n",
    "            ]\n",
    "        )\n",
    "        self.softmax = torch.nn.Softmax(1)\n",
    "\n",
    "    def forward(self, l, *x):\n",
    "        x = list(x)\n",
    "        if len(x) == 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat(x, dim=1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "relation_predicate = ltn.Predicate(MLP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d175702",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_grounding = train_data.get_relations_grounding()\n",
    "obj_grounding = train_data.get_object_grounding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ddbfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(relation_predicate.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        images = data[0]\n",
    "        logic_rules = train_data.get_logic_rules()\n",
    "        axioms = []\n",
    "        for k in logic_rules:\n",
    "            sub = obj_grounding[k[0]]\n",
    "            rel = relation_grounding[k[1]]\n",
    "            objs = logic_rules[k]\n",
    "            y = [obj_grounding[idx] for idx in objs]\n",
    "            y = ltn.Variable('y', torch.stack([idx.value for idx in y]))\n",
    "            x = ltn.Variable('x', images)\n",
    "            axioms += [\n",
    "                Forall(\n",
    "                    [x, y],\n",
    "                    Implies(\n",
    "                        And(\n",
    "                            object_predicate(x, sub),\n",
    "                            relation_predicate(rel, sub, y),\n",
    "                        ),\n",
    "                        object_predicate(x, y),\n",
    "                    ),\n",
    "                )\n",
    "            ]\n",
    "        sat_agg = SatAgg(*axioms)\n",
    "        loss = 1.0 - sat_agg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 20 == 0:\n",
    "            print(\" epoch %d | loss %.4f | Train Sat %.3f \" % (epoch, loss, sat_agg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
