{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "imdb = h5py.File('../data/mini_imdb_1024.h5')\n",
    "sgdb = h5py.File('../data/mini_VG-SGG.h5')\n",
    "\n",
    "import json\n",
    "with open('../data/mini_VG-SGG-dicts.json') as f:\n",
    "    sgdicts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Equiv = ltn.Wrapper_Connective(ltn.fuzzy_ops.Equiv(ltn.fuzzy_ops.And_Prod(),ltn.fuzzy_ops.Implies_Reichenbach()))\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(p=6),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ltn.Variable('image', [i for i in range(100)]) # 1000 images\n",
    "objects = ltn.Variable('object', [i for i in range(50)]) # 150 objects\n",
    "subjects = ltn.Variable('subject', [i for i in range(50)]) \n",
    "relationships = ltn.Variable('relationship', [i for i in range(50)]) # 50 relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_image = defaultdict(set)\n",
    "for image in images.tensor:\n",
    "    image = int(image[0])\n",
    "    if sgdb['img_to_first_box'][image] >= 0:\n",
    "        boxes = [b for b in range(sgdb['img_to_first_box'][image], sgdb['img_to_last_box'][image]+1)]\n",
    "        in_image[image] = set([sgdb['labels'][b][0] for b in boxes])\n",
    "\n",
    "def object_in_image(args):\n",
    "    args = tf.stack(args, axis=1)\n",
    "    output = [0] * args.shape[0]\n",
    "    for i, arg in enumerate(args):\n",
    "        object, image = arg\n",
    "        object, image = int(object), int(image)\n",
    "\n",
    "        if object in in_image[image]:\n",
    "            output[i] = 1\n",
    "\n",
    "    return output\n",
    "\n",
    "obj_in_img = ltn.Predicate(object_in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_in_image = [defaultdict(set) for _ in range(len(imdb['images']))]\n",
    "for image in range(len(imdb['images'])):\n",
    "    if sgdb['img_to_first_rel'][image] >= 0:\n",
    "        relations = [i for i in range(sgdb['img_to_first_rel'][image], sgdb['img_to_last_rel'][image]+1)]\n",
    "        for relation in relations:\n",
    "            predicate = sgdb['predicates'][relation][0]\n",
    "            related_objects = tuple([sgdb['labels'][o][0] for o in sgdb['relationships'][relation].tolist()])\n",
    "            related_in_image[image][predicate].add(related_objects)\n",
    "\n",
    "def relationship_in_image(args):\n",
    "    output = []\n",
    "\n",
    "    for relationship, subject, object, image in zip(*args):\n",
    "        relationship = int(relationship)\n",
    "        subject, object = int(subject), int(object)\n",
    "        image = int(image)\n",
    "\n",
    "        if (subject, object) in related_in_image[image][relationship]:\n",
    "            output.append(1)\n",
    "        else:\n",
    "            output.append(0)\n",
    "\n",
    "    return output\n",
    "\n",
    "rel_in_img = ltn.Predicate(relationship_in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConnected(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ModelConnected, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation=tf.nn.elu)\n",
    "        self.dense2 = tf.keras.layers.Dense(16, activation=tf.nn.elu)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        relation, subject, object = inputs \n",
    "        x = tf.concat([relation, subject, object], axis=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "    \n",
    "Connected = ltn.Predicate(ModelConnected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.999533>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "\n",
    "@tf.function\n",
    "def axioms():\n",
    "    axioms = [\n",
    "        Forall(\n",
    "            [images, relationships, subjects, objects],\n",
    "            Implies(\n",
    "                And(\n",
    "                    And(\n",
    "                        obj_in_img([subjects, images]),\n",
    "                        obj_in_img([objects, images])\n",
    "                    ),\n",
    "                    rel_in_img([relationships, subjects, objects, images])\n",
    "                ),\n",
    "                Connected([relationships, subjects, objects])\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    kb = formula_aggregator(axioms)\n",
    "    sat = kb.tensor\n",
    "    return sat\n",
    "\n",
    "axioms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "\n",
    "for epoch in range(1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1 - axioms()\n",
    "        gradients = tape.gradient(loss, Connected.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, Connected.trainable_variables))\n",
    "        print(f'Epoch:{epoch} Loss:{loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.00024721878862793575\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "relations = len(sgdb['relationships'])\n",
    "for image in related_in_image:\n",
    "    for relation in image:\n",
    "        for subject, object in image[relation]:\n",
    "            sub = ltn.Constant(subject, trainable=False)\n",
    "            obj = ltn.Constant(object, trainable=False)\n",
    "            \n",
    "            prediction = int(tf.argmax(Connected([relationships, sub, obj]).tensor).numpy())\n",
    "            if prediction == relation:\n",
    "                accuracy += 1\n",
    "\n",
    "print(f'ACCURACY: {accuracy / relations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_positives = 0\n",
    "False_positives = 0\n",
    "relations = len(sgdb['relationships'])\n",
    "for image in related_in_image:\n",
    "    for relation in image:\n",
    "        for subject, object in image[relation]:\n",
    "            sub = ltn.Constant(subject, trainable=False)\n",
    "            obj = ltn.Constant(object, trainable=False)\n",
    "            \n",
    "            prediction = int(tf.argmax(Connected([relationships, sub, obj]).tensor).numpy())\n",
    "            if prediction == relation:\n",
    "                True_positives += 1\n",
    "            elif:\n",
    "              False_positives += 1\n",
    "\n",
    "print(f'PRECISION: {True_positives / (False_positives+True_positives)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(related_in_image[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([150, 50])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = obj_in_img([objects, images])\n",
    "test.tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat = ltn.Constant(1, trainable=False)\n",
    "bat = ltn.Constant(1, trainable=False)\n",
    "image1 = ltn.Constant(0, trainable=False)\n",
    "\n",
    "test = obj_in_img([hat, image1])\n",
    "test.tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "image is not a free variable occurring in the expression.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/gvipat/Documents/PRProject/logic_rules/ltn2.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gvipat/Documents/PRProject/logic_rules/ltn2.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test\u001b[39m.\u001b[39;49mtake(\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ltn/core.py:41\u001b[0m, in \u001b[0;36mExpression.take\u001b[0;34m(self, free_var, indices)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGive a single indice or a list of indices.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_copy()\n\u001b[0;32m---> 41\u001b[0m result\u001b[39m.\u001b[39mtensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mgather(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensor, indices, axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis_of_free_var(free_var))\n\u001b[1;32m     42\u001b[0m result\u001b[39m.\u001b[39mfree_vars \u001b[39m=\u001b[39m remaining_free_vars\n\u001b[1;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ltn/core.py:26\u001b[0m, in \u001b[0;36mExpression._get_axis_of_free_var\u001b[0;34m(self, free_var)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_axis_of_free_var\u001b[39m(\u001b[39mself\u001b[39m, free_var: VarLabel) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mif\u001b[39;00m free_var \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_vars:\n\u001b[0;32m---> 26\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not a free variable occurring in the expression.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39mfree_var)\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_vars\u001b[39m.\u001b[39mindex(free_var)\n",
      "\u001b[0;31mValueError\u001b[0m: image is not a free variable occurring in the expression."
     ]
    }
   ],
   "source": [
    "test.take('image', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 150])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "touching = ltn.Constant(0, trainable=False)\n",
    "\n",
    "test = rel_in_img([relationships, subjects, hat, image1])\n",
    "test.tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ltn.Formula(tensor=[0.70203084 0.71996546 0.7314017  0.75179565 0.7779284  0.8053186\n",
       " 0.8314769  0.8554006  0.8768152  0.8957781  0.9124077  0.9268533\n",
       " 0.9392937  0.9499198  0.9589253  0.9665008  0.9728282  0.97807753\n",
       " 0.98239017 0.9858999  0.98874307 0.9910366  0.9928798  0.99435633\n",
       " 0.99553543 0.9964743  0.9972198  0.9978106  0.99827784 0.99864686\n",
       " 0.99893785 0.99916697 0.99934727 0.9994889  0.99960005 0.99968725\n",
       " 0.99975556 0.9998091  0.9998509  0.99988365 0.9999092  0.99992925\n",
       " 0.9999448  0.999957   0.9999665  0.9999739  0.9999797  0.9999842\n",
       " 0.9999877  0.9999904 ], free_vars=['relationship'])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Connected([relationships, hat, hat])\n",
    "am = tf.argmax(test.tensor)\n",
    "am.numpy()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ltn.Formula(tensor=0.01987755298614502, free_vars=[])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forall(\n",
    "    [images, subjects],\n",
    "    obj_in_img([subjects, images])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1, 2, 3])\n",
    "b = tf.constant([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([a, b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4045"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sgdb['relationships'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
